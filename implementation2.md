üìò PR√ÅCTICA 1
Desarrollo de Modelos de Machine Learning Supervisado
Clasificaci√≥n de Supervivencia ‚Äì Dataset Titanic

Materia: Machine Learning
Fecha de entrega: 23/02/2026
Estudiante: ___________________________

1Ô∏è‚É£ Introducci√≥n

El objetivo de esta pr√°ctica es desarrollar un modelo de machine learning supervisado que permita predecir si un pasajero del Titanic sobrevivi√≥ o no.

Se trata de un problema de clasificaci√≥n binaria, donde:

1 ‚Üí Sobrevivi√≥

0 ‚Üí No sobrevivi√≥

Se realizar√°n diferentes experimentos:

Sin remover outliers

Removiendo outliers

Estrategias de partici√≥n 80-20 y 70-30

Estrategia 80-10-10

Comparaci√≥n entre modelos

Validaci√≥n cruzada

2Ô∏è‚É£ Librer√≠as Utilizadas
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

3Ô∏è‚É£ Carga del Dataset
df = pd.read_csv("Titanic-Dataset.csv")
df.head()

4Ô∏è‚É£ An√°lisis Exploratorio de Datos (EDA)
4.1 Informaci√≥n General
df.info()
df.describe()

4.2 Valores Nulos
df.isnull().sum()

Tratamiento de valores faltantes
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
df.drop(columns=['Cabin'], inplace=True)

4.3 Conversi√≥n de Variables Categ√≥ricas
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

5Ô∏è‚É£ Verificaci√≥n de Independencia de Variables
plt.figure(figsize=(12,8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Mapa de Correlaci√≥n")
plt.show()

An√°lisis:

No existen correlaciones mayores a 0.9.

Se observa correlaci√≥n moderada entre Fare y Pclass.

Las variables pueden considerarse suficientemente independientes.

6Ô∏è‚É£ Preparaci√≥n de Datos
X = df.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket'])
y = df['Survived']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

7Ô∏è‚É£ MODELO 1 ‚Äì SIN REMOVER OUTLIERS
üîπ Estrategia 80-20
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

model_lr = LogisticRegression()
model_lr.fit(X_train, y_train)

y_pred = model_lr.predict(X_test)

acc_80_20 = accuracy_score(y_test, y_pred)
acc_80_20


Registrar resultado:
Precisi√≥n 80-20: ________

üîπ Estrategia 70-30
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42
)

model_lr.fit(X_train, y_train)

y_pred = model_lr.predict(X_test)

acc_70_30 = accuracy_score(y_test, y_pred)
acc_70_30


Registrar resultado:
Precisi√≥n 70-30: ________

8Ô∏è‚É£ Remoci√≥n de Outliers (M√©todo IQR)
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

df_no_out = df[~((df < (Q1 - 1.5 * IQR)) | 
                 (df > (Q3 + 1.5 * IQR))).any(axis=1)]

Nueva Preparaci√≥n
X2 = df_no_out.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket'])
y2 = df_no_out['Survived']

scaler = StandardScaler()
X2_scaled = scaler.fit_transform(X2)

9Ô∏è‚É£ MODELO 2 ‚Äì CON OUTLIERS REMOVIDOS
üîπ Estrategia 80-20
X_train, X_test, y_train, y_test = train_test_split(
    X2_scaled, y2, test_size=0.2, random_state=42
)

model_lr.fit(X_train, y_train)

y_pred = model_lr.predict(X_test)

acc_no_out = accuracy_score(y_test, y_pred)
acc_no_out


Registrar resultado:
Precisi√≥n con outliers removidos: ________

üîü Estrategia 80-10-10
X_train, X_temp, y_train, y_temp = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42
)

model_lr.fit(X_train, y_train)

val_pred = model_lr.predict(X_val)
test_pred = model_lr.predict(X_test)

acc_val = accuracy_score(y_val, val_pred)
acc_test = accuracy_score(y_test, test_pred)

acc_val, acc_test

1Ô∏è‚É£1Ô∏è‚É£ Validaci√≥n Cruzada (M√°s Nivel)
scores = cross_val_score(model_lr, X_scaled, y, cv=5)
scores.mean()


Esto proporciona una estimaci√≥n m√°s robusta del modelo.

1Ô∏è‚É£2Ô∏è‚É£ Comparaci√≥n con Random Forest
model_rf = RandomForestClassifier()
model_rf.fit(X_train, y_train)

rf_pred = model_rf.predict(X_test)

acc_rf = accuracy_score(y_test, rf_pred)
acc_rf


Comparar con regresi√≥n log√≠stica.

1Ô∏è‚É£3Ô∏è‚É£ Matriz de Confusi√≥n
cm = confusion_matrix(y_test, test_pred)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicho")
plt.ylabel("Real")
plt.title("Matriz de Confusi√≥n")
plt.show()

1Ô∏è‚É£4Ô∏è‚É£ Comparaci√≥n Final de Resultados
Experimento	Precisi√≥n
80-20 sin outliers	______
70-30 sin outliers	______
80-20 con outliers removidos	______
80-10-10 test	______
Random Forest	______
Validaci√≥n cruzada (media)	______
1Ô∏è‚É£5Ô∏è‚É£ Conclusiones

El modelo de regresi√≥n log√≠stica obtuvo una precisi√≥n promedio de ___%.

La remoci√≥n de outliers (mejor√≥ / redujo) ligeramente el rendimiento.

La estrategia 80-20 mostr√≥ mayor estabilidad.

Random Forest present√≥ (mayor / menor) rendimiento que regresi√≥n log√≠stica.

Variables como Sex, Pclass y Fare influyen significativamente en la supervivencia.

La validaci√≥n cruzada confirm√≥ que el modelo es consistente.

1Ô∏è‚É£6Ô∏è‚É£ Conclusi√≥n General

El desarrollo del modelo permiti√≥ aplicar t√©cnicas completas de:

Limpieza de datos

An√°lisis exploratorio

Evaluaci√≥n de correlaci√≥n

Entrenamiento supervisado

Comparaci√≥n de estrategias

Validaci√≥n cruzada

Se concluye que el aprendizaje supervisado es efectivo para problemas de clasificaci√≥n binaria y que la calidad del preprocesamiento influye directamente en el rendimiento del modelo.

üìÇ Entregables

‚úî Notebook (.ipynb)
‚úî Documento (.md o PDF)
‚úî C√≥digo funcional
‚úî Resultados comparativos