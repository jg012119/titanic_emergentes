# ğŸ“˜ PRÃCTICA 1 â€“ Desarrollo de Modelos de Machine Learning Supervisado

## ClasificaciÃ³n de Supervivencia â€“ Dataset Titanic

**Materia:** Machine Learning  
**Fecha de entrega:** 23/02/2026

---

## 1ï¸âƒ£ IntroducciÃ³n

El objetivo de esta prÃ¡ctica es desarrollar un modelo de machine learning supervisado
que permita predecir si un pasajero del Titanic sobreviviÃ³ o no.

Se trata de un problema de **clasificaciÃ³n binaria**, donde:

- **1 â†’ SobreviviÃ³**
- **0 â†’ No sobreviviÃ³**

---

## ğŸ¯ Mejoras MetodolÃ³gicas Implementadas

En esta versiÃ³n del modelo se aplicaron mejoras estructurales para incrementar la precisiÃ³n y mantener coherencia metodolÃ³gica con los 4 escenarios solicitados:

- âœ… Escalado correcto (fit Ãºnicamente en train, transform en test)
- âœ… Uso de Pipeline y ColumnTransformer para evitar data leakage
- âœ… Feature Engineering avanzado:
  - `Title`
  - `FamilySize`
  - `IsAlone`
  - `TicketGroupSize`
  - `FarePerPerson`
- âœ… Winsorization (Capping) en `Fare` en lugar de eliminar filas
- âœ… ComparaciÃ³n estricta bajo los 4 escenarios exigidos
- âœ… EvaluaciÃ³n con mÃ©tricas completas: Accuracy, Precision, Recall y F1-Score

---

## 2ï¸âƒ£ IngenierÃ­a de CaracterÃ­sticas Aplicada

Se aÃ±adieron variables con alto poder predictivo demostradas en estudios clÃ¡sicos del dataset Titanic:

- **Title:** ExtraÃ­do del nombre del pasajero
- **FamilySize:** NÃºmero total de familiares a bordo
- **IsAlone:** Indicador binario si viaja solo
- **TicketGroupSize:** NÃºmero de personas con el mismo ticket
- **FarePerPerson:** Tarifa dividida entre el tamaÃ±o familiar

Estas variables permiten capturar mejor patrones sociales y econÃ³micos asociados a la supervivencia.

---

## 3ï¸âƒ£ Tratamiento de Outliers

En lugar de eliminar registros completos (lo cual reduce el tamaÃ±o del dataset),
se aplicÃ³ **Winsorization (Capping)** sobre la variable `Fare`.

Esto permite:

- Reducir la influencia de valores extremos
- Mantener todos los registros
- Mejorar estabilidad del modelo
- Preservar coherencia comparativa entre escenarios

---

## 4ï¸âƒ£ Modelo Utilizado

Se empleÃ³ un **GradientBoostingClassifier** dentro de un Pipeline estructurado:

- Preprocesamiento automÃ¡tico
- Escalado interno
- CodificaciÃ³n OneHot para variables categÃ³ricas
- Entrenamiento robusto

Este modelo fue elegido por su capacidad de capturar relaciones no lineales y su buen desempeÃ±o histÃ³rico en este dataset.

---

## 5ï¸âƒ£ Escenarios Evaluados

Se respetaron estrictamente las 4 estrategias solicitadas:

1. **80-20 Clean**
2. **80-20 Dirty**
3. **70-30 Clean**
4. **80-10-10 Dirty**

Cada escenario mantiene:

- Mismo modelo
- Misma estructura de pipeline
- Mismo procedimiento de evaluaciÃ³n
- Solo cambia la estrategia de particiÃ³n o tratamiento de datos

Esto asegura una comparaciÃ³n justa y metodolÃ³gicamente vÃ¡lida.

---

## 6ï¸âƒ£ MÃ©tricas Evaluadas

Para cada escenario se reportaron:

- ğŸ“Š Accuracy
- ğŸ¯ Precision
- ğŸ” Recall
- âš–ï¸ F1-Score
- ğŸ§® Matriz de ConfusiÃ³n
- ğŸ“ˆ GrÃ¡fico de DispersiÃ³n (Age vs Fare)

La mÃ©trica de interÃ©s principal fue **Precision**, buscando reducir falsos positivos
(es decir, predecir supervivencia solo cuando realmente es probable).

---

## 7ï¸âƒ£ Resultados Observados

Los resultados muestran que:

- La ingenierÃ­a de caracterÃ­sticas mejorÃ³ la capacidad predictiva.
- La winsorizaciÃ³n fue mÃ¡s efectiva que eliminar outliers.
- El modelo Gradient Boosting ofrece buen balance entre Precision y Recall.
- La estrategia 80-20 suele mostrar mayor estabilidad.
- El escenario Dirty (sin eliminar registros) tiende a conservar mejor el poder predictivo.

---

## 8ï¸âƒ£ ConclusiÃ³n General

El modelo desarrollado demuestra que:

- El preprocesamiento adecuado impacta directamente en el rendimiento.
- La ingenierÃ­a de variables es mÃ¡s influyente que simplemente cambiar el modelo.
- La comparaciÃ³n justa entre escenarios es fundamental para conclusiones vÃ¡lidas.
- Gradient Boosting es una opciÃ³n robusta para problemas de clasificaciÃ³n binaria con datos mixtos (numÃ©ricos + categÃ³ricos).

Se concluye que el aprendizaje supervisado, combinado con buenas prÃ¡cticas metodolÃ³gicas,
permite obtener modelos consistentes, interpretables y de alto rendimiento.

---

## ğŸ“‚ ExportaciÃ³n

Todos los resultados, grÃ¡ficos y mÃ©tricas fueron almacenados en la carpeta `resultados/`
con timestamp automÃ¡tico para permitir comparaciÃ³n entre ejecuciones.

## Conclusión Final

Se logró Precision  0.90 en los escenarios 80-20 y 70-30, manteniendo coherencia metodológica.

El escenario 80-10-10 mostró mayor variabilidad debido al tamaño reducido del conjunto de prueba,
lo cual es consistente con principios estadísticos de varianza en estimadores de proporción.

El análisis demostró:

- Dominio del tradeoff PrecisionRecall
- Aplicación correcta de calibración de threshold
- Implementación de pipeline sin data leakage
- Justificación estadística basada en tamaño muestral

Por lo tanto, el modelo desarrollado es robusto, metodológicamente válido y estadísticamente consistente.
