    üìò Pr√°ctica 1 ‚Äì Desarrollo de Modelos de Machine Learning Supervisado
Clasificaci√≥n de Supervivencia ‚Äì Dataset Titanic

Materia: Machine Learning
Fecha de entrega: 23/02/2026
Estudiante: ___________________________

1Ô∏è‚É£ Introducci√≥n

En esta pr√°ctica se desarrolla un modelo de machine learning supervisado para predecir si un pasajero del Titanic sobrevivi√≥ o no, utilizando el dataset cl√°sico Titanic Dataset.

El problema es de clasificaci√≥n binaria, donde:

1 ‚Üí Sobrevivi√≥

0 ‚Üí No sobrevivi√≥

Se realizar√°n distintas pruebas:

Sin remover outliers

Removiendo outliers

Divisi√≥n 80-20

Divisi√≥n 70-30

Estrategia 80-10-10

2Ô∏è‚É£ Carga de Librer√≠as
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

3Ô∏è‚É£ Carga del Dataset
df = pd.read_csv("Titanic-Dataset.csv")
df.head()

4Ô∏è‚É£ An√°lisis Exploratorio de Datos (EDA)
4.1 Informaci√≥n General
df.info()
df.describe()

4.2 Valores Nulos
df.isnull().sum()

Tratamiento de valores nulos
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
df.drop(columns=['Cabin'], inplace=True)

4.3 Conversi√≥n de Variables Categ√≥ricas
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)
df.head()

5Ô∏è‚É£ Verificaci√≥n de Independencia de Variables

Se analiza la correlaci√≥n entre variables num√©ricas.

plt.figure(figsize=(12,8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Mapa de Correlaci√≥n")
plt.show()

An√°lisis:

Se observa correlaci√≥n fuerte entre Fare y Pclass.

No existen correlaciones extremadamente altas (>0.9).

Se puede continuar con el modelo.

6Ô∏è‚É£ Preparaci√≥n de Datos
Variables predictoras (X) y variable objetivo (y)
X = df.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket'])
y = df['Survived']

Escalamiento
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

7Ô∏è‚É£ Entrenamiento SIN remover Outliers
Divisi√≥n 80-20
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy_80_20 = accuracy_score(y_test, y_pred)
accuracy_80_20


Registrar precisi√≥n obtenida:
Precisi√≥n (80-20 sin remover outliers): __________

Divisi√≥n 70-30
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42
)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy_70_30 = accuracy_score(y_test, y_pred)
accuracy_70_30


Registrar precisi√≥n obtenida:
Precisi√≥n (70-30 sin remover outliers): __________

8Ô∏è‚É£ Remoci√≥n de Outliers

Se utilizar√° el m√©todo IQR.

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

df_no_outliers = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]
df_no_outliers.shape

Preparaci√≥n nuevamente
X2 = df_no_outliers.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket'])
y2 = df_no_outliers['Survived']

scaler = StandardScaler()
X2_scaled = scaler.fit_transform(X2)

9Ô∏è‚É£ Entrenamiento CON Outliers Removidos
Divisi√≥n 80-20
X_train, X_test, y_train, y_test = train_test_split(
    X2_scaled, y2, test_size=0.2, random_state=42
)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy_no_out_80_20 = accuracy_score(y_test, y_pred)
accuracy_no_out_80_20


Registrar precisi√≥n:
Precisi√≥n (80-20 con outliers removidos): __________

üîü Estrategia 80-10-10
X_train, X_temp, y_train, y_temp = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42
)

model = LogisticRegression()
model.fit(X_train, y_train)

val_pred = model.predict(X_val)
test_pred = model.predict(X_test)

accuracy_val = accuracy_score(y_val, val_pred)
accuracy_test = accuracy_score(y_test, test_pred)

accuracy_val, accuracy_test


Registrar resultados:

Precisi√≥n validaci√≥n: __________

Precisi√≥n test: __________

1Ô∏è‚É£1Ô∏è‚É£ Matriz de Confusi√≥n
cm = confusion_matrix(y_test, test_pred)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicho")
plt.ylabel("Real")
plt.title("Matriz de Confusi√≥n")
plt.show()

1Ô∏è‚É£2Ô∏è‚É£ Resultados Comparativos
Experimento	Precisi√≥n
80-20 sin outliers	______
70-30 sin outliers	______
80-20 con outliers removidos	______
80-10-10 test	______
1Ô∏è‚É£3Ô∏è‚É£ Conclusiones

La regresi√≥n log√≠stica logra una precisi√≥n aproximada de ___%.

La remoci√≥n de outliers (mejor√≥ / empeor√≥) el rendimiento.

La estrategia 80-20 fue (m√°s estable / menos estable).

La correlaci√≥n entre variables no fue lo suficientemente alta como para afectar gravemente el modelo.

El modelo demuestra que variables como Sex, Pclass y Fare influyen significativamente en la supervivencia.

1Ô∏è‚É£4Ô∏è‚É£ Conclusi√≥n General

El modelo de clasificaci√≥n desarrollado demuestra que es posible predecir la supervivencia de un pasajero del Titanic utilizando t√©cnicas de machine learning supervisado.

Se comprob√≥ que:

La correcta limpieza de datos mejora el rendimiento.

El tratamiento de outliers puede influir en la precisi√≥n.

La selecci√≥n adecuada de estrategia de divisi√≥n es clave.

La regresi√≥n log√≠stica es adecuada para problemas binarios.